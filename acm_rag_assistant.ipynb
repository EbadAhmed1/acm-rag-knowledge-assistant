{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593129c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import requests\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "DB_DIR = \"vector_db\"\n",
    "RELEVANCE_THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fba879",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"your-api-key\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\", \"your-serper-api-key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"knowledge-base\"]\n",
    "documents = []\n",
    "\n",
    "for folder in folders:\n",
    "    loader = DirectoryLoader(\n",
    "        folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs={\"encoding\": \"utf-8\"}\n",
    "    )\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Loaded {len(chunks)} chunks from knowledge base.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Reset vector db\n",
    "if os.path.exists(DB_DIR):\n",
    "    shutil.rmtree(DB_DIR)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=DB_DIR)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a582dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL, temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the context below in a natural, conversational way.\n",
    "If you cannot answer based on the context, say so briefly.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Answer:\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "qa_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e496b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serper_search(query: str, num_results: int = 5) -> List[Dict]:\n",
    "    \"\"\"Perform web search using Serper API with FAST University Karachi context\"\"\"\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    \n",
    "    # Add FAST University Karachi context to make searches more relevant\n",
    "    enhanced_query = f\"{query} FAST University Karachi\"\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": enhanced_query,\n",
    "        \"num\": num_results\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"X-API-KEY\": SERPER_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "        \n",
    "        search_results = []\n",
    "        if \"organic\" in results:\n",
    "            for result in results[\"organic\"]:\n",
    "                search_results.append({\n",
    "                    \"title\": result.get(\"title\", \"\"),\n",
    "                    \"snippet\": result.get(\"snippet\", \"\"),\n",
    "                    \"link\": result.get(\"link\", \"\")\n",
    "                })\n",
    "        \n",
    "        return search_results\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Serper search: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ea3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_rag_response_relevant(source_documents: List[Document], answer: str, threshold: float = RELEVANCE_THRESHOLD) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if RAG retrieved relevant documents and provided a useful answer.\n",
    "    Adjusted to trust RAG more (60% confidence in RAG).\n",
    "    \"\"\"\n",
    "    if not source_documents:\n",
    "        return False\n",
    "    \n",
    "    total_content_length = sum(len(doc.page_content.strip()) for doc in source_documents)\n",
    "    if total_content_length < 80:  # Lower threshold to trust RAG more\n",
    "        return False\n",
    "    \n",
    "    # Only reject if answer explicitly says it cannot answer\n",
    "    strong_refusal_phrases = [\n",
    "        \"cannot answer\",\n",
    "        \"don't have information\",\n",
    "        \"no information\",\n",
    "        \"context does not provide\",\n",
    "        \"not available in the context\"\n",
    "    ]\n",
    "    \n",
    "    answer_lower = answer.lower()\n",
    "    for phrase in strong_refusal_phrases:\n",
    "        if phrase in answer_lower:\n",
    "            return False\n",
    "    \n",
    "    # Trust short answers more (reduced from 50 to 30)\n",
    "    if len(answer.strip()) < 30:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9968024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_web_search(question: str, search_results: List[Dict]) -> str:\n",
    "    \"\"\"Use LLM to answer question based on web search results in a conversational way\"\"\"\n",
    "    llm = ChatOpenAI(model=MODEL, temperature=0.3)\n",
    "    \n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Source: {r['title']}\\n{r['snippet']}\\nURL: {r['link']}\"\n",
    "        for r in search_results\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"Based on the web search results below, answer the question naturally as if you're having a conversation.\n",
    "Don't mention that you're using web search results. Just provide a helpful, conversational answer.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Search Results:\n",
    "{context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
